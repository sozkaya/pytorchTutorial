{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projected_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sozkaya/pytorchTutorial/blob/master/projectedgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUaixszCnlKd"
      },
      "source": [
        "\n",
        "# Training Projected GAN\n",
        "This is a self-contained notebook for training Projected GAN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBwzYACTn05w"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. \n",
        "\n",
        "Now, get the repo and install missing dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ3pwUJSoOdO"
      },
      "source": [
        "%%capture\n",
        "%%bash\n",
        "# clone repo\n",
        "git clone https://github.com/autonomousvision/projected_gan\n",
        "pip install timm==0.5.4"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4N21o-gzMjB",
        "outputId": "1c93d528-2d48-46df-a9a6-2b7cf517ffe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd projected_gan"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/projected_gan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0hD7dKQR00t"
      },
      "source": [
        "## Data Preparation\n",
        "We need to download and prepare the data. In this example, we use the few-shot datasets of the [FastGAN repo](https://github.com/odegeasslbc/FastGAN-pytorch)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mz2_Eynze8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ff9956-8036-4a6e-d0f4-a00a541d722d"
      },
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=1aAJCZbXNHyraJ6Mi13dSbe7pTyfPXha0&export=download"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1aAJCZbXNHyraJ6Mi13dSbe7pTyfPXha0\n",
            "To: /content/projected_gan/few-shot-image-datasets.zip\n",
            "100% 913M/913M [00:03<00:00, 249MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6NTT3zVzesu"
      },
      "source": [
        "%%capture\n",
        "!unzip few-shot-image-datasets.zip\n",
        "!mv few-shot-images data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TnMmxJrPFZs",
        "outputId": "32c8f5e2-645a-4660-c65b-722272d1e882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash\n",
        "python dataset_tool.py --source=./data/art-painting --dest=./data/art_painting256.zip --resolution=256x256"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]\r  1%|          | 6/1000 [00:00<00:18, 53.63it/s]\r  1%|          | 12/1000 [00:00<00:17, 55.79it/s]\r  2%|▏         | 18/1000 [00:00<00:17, 54.98it/s]\r  2%|▏         | 24/1000 [00:00<00:17, 55.65it/s]\r  3%|▎         | 30/1000 [00:00<00:17, 56.32it/s]\r  4%|▎         | 36/1000 [00:00<00:17, 56.49it/s]\r  4%|▍         | 42/1000 [00:00<00:16, 56.72it/s]\r  5%|▍         | 48/1000 [00:00<00:16, 57.30it/s]\r  5%|▌         | 54/1000 [00:00<00:16, 57.69it/s]\r  6%|▌         | 60/1000 [00:01<00:16, 58.02it/s]\r  7%|▋         | 66/1000 [00:01<00:16, 58.25it/s]\r  7%|▋         | 72/1000 [00:01<00:16, 57.21it/s]\r  8%|▊         | 79/1000 [00:01<00:15, 58.16it/s]\r  8%|▊         | 85/1000 [00:01<00:15, 58.04it/s]\r  9%|▉         | 91/1000 [00:01<00:15, 58.51it/s]\r 10%|▉         | 97/1000 [00:01<00:15, 56.99it/s]\r 10%|█         | 103/1000 [00:01<00:15, 57.55it/s]\r 11%|█         | 109/1000 [00:01<00:15, 57.57it/s]\r 12%|█▏        | 115/1000 [00:02<00:15, 57.22it/s]\r 12%|█▏        | 121/1000 [00:02<00:16, 53.47it/s]\r 13%|█▎        | 127/1000 [00:02<00:16, 54.52it/s]\r 13%|█▎        | 133/1000 [00:02<00:15, 54.78it/s]\r 14%|█▍        | 139/1000 [00:02<00:15, 55.42it/s]\r 14%|█▍        | 145/1000 [00:02<00:15, 56.19it/s]\r 15%|█▌        | 151/1000 [00:02<00:15, 56.41it/s]\r 16%|█▌        | 157/1000 [00:02<00:14, 56.41it/s]\r 16%|█▋        | 163/1000 [00:02<00:14, 56.41it/s]\r 17%|█▋        | 169/1000 [00:02<00:14, 56.41it/s]\r 18%|█▊        | 175/1000 [00:03<00:14, 55.85it/s]\r 18%|█▊        | 181/1000 [00:03<00:14, 55.94it/s]\r 19%|█▊        | 187/1000 [00:03<00:14, 56.14it/s]\r 19%|█▉        | 193/1000 [00:03<00:14, 56.59it/s]\r 20%|█▉        | 199/1000 [00:03<00:13, 57.28it/s]\r 20%|██        | 205/1000 [00:03<00:13, 57.52it/s]\r 21%|██        | 211/1000 [00:03<00:13, 57.73it/s]\r 22%|██▏       | 217/1000 [00:03<00:13, 57.85it/s]\r 22%|██▏       | 224/1000 [00:03<00:13, 58.45it/s]\r 23%|██▎       | 230/1000 [00:04<00:13, 58.84it/s]\r 24%|██▎       | 236/1000 [00:04<00:13, 58.60it/s]\r 24%|██▍       | 242/1000 [00:04<00:12, 58.54it/s]\r 25%|██▍       | 248/1000 [00:04<00:12, 57.90it/s]\r 25%|██▌       | 254/1000 [00:04<00:12, 58.19it/s]\r 26%|██▌       | 261/1000 [00:04<00:12, 58.84it/s]\r 27%|██▋       | 267/1000 [00:04<00:12, 58.56it/s]\r 27%|██▋       | 273/1000 [00:04<00:12, 58.25it/s]\r 28%|██▊       | 279/1000 [00:04<00:12, 57.69it/s]\r 28%|██▊       | 285/1000 [00:04<00:12, 57.65it/s]\r 29%|██▉       | 291/1000 [00:05<00:12, 58.25it/s]\r 30%|██▉       | 297/1000 [00:05<00:12, 58.21it/s]\r 30%|███       | 303/1000 [00:05<00:11, 58.14it/s]\r 31%|███       | 309/1000 [00:05<00:11, 57.82it/s]\r 32%|███▏      | 315/1000 [00:05<00:11, 57.55it/s]\r 32%|███▏      | 321/1000 [00:05<00:11, 57.80it/s]\r 33%|███▎      | 327/1000 [00:05<00:11, 57.87it/s]\r 33%|███▎      | 333/1000 [00:05<00:11, 57.86it/s]\r 34%|███▍      | 339/1000 [00:05<00:11, 57.72it/s]\r 34%|███▍      | 345/1000 [00:06<00:11, 58.13it/s]\r 35%|███▌      | 351/1000 [00:06<00:11, 57.86it/s]\r 36%|███▌      | 357/1000 [00:06<00:11, 58.12it/s]\r 36%|███▋      | 363/1000 [00:06<00:11, 56.93it/s]\r 37%|███▋      | 369/1000 [00:06<00:11, 57.03it/s]\r 38%|███▊      | 375/1000 [00:06<00:10, 57.53it/s]\r 38%|███▊      | 381/1000 [00:06<00:10, 58.07it/s]\r 39%|███▊      | 387/1000 [00:06<00:10, 58.19it/s]\r 39%|███▉      | 393/1000 [00:06<00:10, 58.45it/s]\r 40%|███▉      | 399/1000 [00:06<00:10, 58.48it/s]\r 40%|████      | 405/1000 [00:07<00:10, 58.73it/s]\r 41%|████      | 411/1000 [00:07<00:10, 58.58it/s]\r 42%|████▏     | 417/1000 [00:07<00:10, 56.94it/s]\r 42%|████▏     | 423/1000 [00:07<00:10, 56.62it/s]\r 43%|████▎     | 429/1000 [00:07<00:09, 57.46it/s]\r 44%|████▎     | 435/1000 [00:07<00:09, 57.99it/s]\r 44%|████▍     | 441/1000 [00:07<00:09, 58.23it/s]\r 45%|████▍     | 447/1000 [00:07<00:09, 57.94it/s]\r 45%|████▌     | 453/1000 [00:07<00:09, 57.66it/s]\r 46%|████▌     | 459/1000 [00:07<00:09, 57.78it/s]\r 46%|████▋     | 465/1000 [00:08<00:09, 57.63it/s]\r 47%|████▋     | 471/1000 [00:08<00:09, 58.27it/s]\r 48%|████▊     | 477/1000 [00:08<00:08, 58.53it/s]\r 48%|████▊     | 483/1000 [00:08<00:08, 57.86it/s]\r 49%|████▉     | 489/1000 [00:08<00:08, 57.94it/s]\r 50%|████▉     | 496/1000 [00:08<00:08, 58.76it/s]\r 50%|█████     | 502/1000 [00:08<00:08, 58.57it/s]\r 51%|█████     | 508/1000 [00:08<00:08, 58.78it/s]\r 51%|█████▏    | 514/1000 [00:08<00:08, 58.68it/s]\r 52%|█████▏    | 520/1000 [00:09<00:08, 58.19it/s]\r 53%|█████▎    | 526/1000 [00:09<00:08, 58.46it/s]\r 53%|█████▎    | 532/1000 [00:09<00:07, 58.77it/s]\r 54%|█████▍    | 538/1000 [00:09<00:07, 58.27it/s]\r 54%|█████▍    | 544/1000 [00:09<00:07, 57.81it/s]\r 55%|█████▌    | 550/1000 [00:09<00:07, 58.14it/s]\r 56%|█████▌    | 556/1000 [00:09<00:07, 58.27it/s]\r 56%|█████▌    | 562/1000 [00:09<00:07, 58.18it/s]\r 57%|█████▋    | 568/1000 [00:09<00:07, 57.52it/s]\r 57%|█████▋    | 574/1000 [00:09<00:07, 58.02it/s]\r 58%|█████▊    | 580/1000 [00:10<00:07, 58.13it/s]\r 59%|█████▊    | 586/1000 [00:10<00:07, 58.45it/s]\r 59%|█████▉    | 592/1000 [00:10<00:06, 58.45it/s]\r 60%|█████▉    | 599/1000 [00:10<00:06, 58.47it/s]\r 61%|██████    | 606/1000 [00:10<00:06, 59.10it/s]\r 61%|██████    | 612/1000 [00:10<00:06, 59.23it/s]\r 62%|██████▏   | 618/1000 [00:10<00:06, 58.72it/s]\r 62%|██████▏   | 624/1000 [00:10<00:06, 58.67it/s]\r 63%|██████▎   | 631/1000 [00:10<00:06, 59.08it/s]\r 64%|██████▎   | 637/1000 [00:11<00:06, 59.07it/s]\r 64%|██████▍   | 643/1000 [00:11<00:06, 58.62it/s]\r 65%|██████▍   | 649/1000 [00:11<00:05, 58.75it/s]\r 66%|██████▌   | 655/1000 [00:11<00:05, 58.73it/s]\r 66%|██████▌   | 661/1000 [00:11<00:05, 57.51it/s]\r 67%|██████▋   | 667/1000 [00:11<00:06, 52.42it/s]\r 67%|██████▋   | 673/1000 [00:11<00:06, 53.70it/s]\r 68%|██████▊   | 679/1000 [00:11<00:05, 53.56it/s]\r 68%|██████▊   | 685/1000 [00:11<00:05, 54.94it/s]\r 69%|██████▉   | 691/1000 [00:12<00:05, 55.96it/s]\r 70%|██████▉   | 697/1000 [00:12<00:05, 56.91it/s]\r 70%|███████   | 703/1000 [00:12<00:05, 52.93it/s]\r 71%|███████   | 709/1000 [00:12<00:05, 50.70it/s]\r 72%|███████▏  | 715/1000 [00:12<00:05, 52.43it/s]\r 72%|███████▏  | 721/1000 [00:12<00:05, 53.85it/s]\r 73%|███████▎  | 727/1000 [00:12<00:04, 55.40it/s]\r 73%|███████▎  | 733/1000 [00:12<00:04, 55.98it/s]\r 74%|███████▍  | 739/1000 [00:12<00:04, 53.55it/s]\r 74%|███████▍  | 745/1000 [00:13<00:04, 54.96it/s]\r 75%|███████▌  | 751/1000 [00:13<00:04, 55.94it/s]\r 76%|███████▌  | 757/1000 [00:13<00:04, 56.91it/s]\r 76%|███████▋  | 763/1000 [00:13<00:04, 56.78it/s]\r 77%|███████▋  | 769/1000 [00:13<00:04, 56.59it/s]\r 78%|███████▊  | 775/1000 [00:13<00:03, 57.21it/s]\r 78%|███████▊  | 781/1000 [00:13<00:03, 57.66it/s]\r 79%|███████▊  | 787/1000 [00:13<00:03, 57.98it/s]\r 79%|███████▉  | 793/1000 [00:13<00:03, 57.90it/s]\r 80%|███████▉  | 799/1000 [00:13<00:03, 57.75it/s]\r 80%|████████  | 805/1000 [00:14<00:03, 57.79it/s]\r 81%|████████  | 811/1000 [00:14<00:03, 57.97it/s]\r 82%|████████▏ | 817/1000 [00:14<00:03, 58.31it/s]\r 82%|████████▏ | 823/1000 [00:14<00:03, 57.82it/s]\r 83%|████████▎ | 829/1000 [00:14<00:02, 57.39it/s]\r 84%|████████▎ | 835/1000 [00:14<00:02, 57.46it/s]\r 84%|████████▍ | 841/1000 [00:14<00:02, 57.98it/s]\r 85%|████████▍ | 847/1000 [00:14<00:02, 57.97it/s]\r 85%|████████▌ | 853/1000 [00:14<00:02, 57.32it/s]\r 86%|████████▌ | 859/1000 [00:14<00:02, 57.27it/s]\r 86%|████████▋ | 865/1000 [00:15<00:02, 57.39it/s]\r 87%|████████▋ | 871/1000 [00:15<00:02, 57.90it/s]\r 88%|████████▊ | 877/1000 [00:15<00:02, 57.98it/s]\r 88%|████████▊ | 883/1000 [00:15<00:02, 57.50it/s]\r 89%|████████▉ | 889/1000 [00:15<00:01, 56.85it/s]\r 90%|████████▉ | 895/1000 [00:15<00:01, 57.71it/s]\r 90%|█████████ | 901/1000 [00:15<00:01, 57.85it/s]\r 91%|█████████ | 907/1000 [00:15<00:01, 58.06it/s]\r 91%|█████████▏| 914/1000 [00:15<00:01, 58.82it/s]\r 92%|█████████▏| 920/1000 [00:16<00:01, 58.85it/s]\r 93%|█████████▎| 926/1000 [00:16<00:01, 58.62it/s]\r 93%|█████████▎| 932/1000 [00:16<00:01, 58.63it/s]\r 94%|█████████▍| 938/1000 [00:16<00:01, 58.72it/s]\r 94%|█████████▍| 944/1000 [00:16<00:00, 58.53it/s]\r 95%|█████████▌| 950/1000 [00:16<00:00, 57.89it/s]\r 96%|█████████▌| 956/1000 [00:16<00:00, 57.85it/s]\r 96%|█████████▌| 962/1000 [00:16<00:00, 58.08it/s]\r 97%|█████████▋| 968/1000 [00:16<00:00, 58.26it/s]\r 97%|█████████▋| 974/1000 [00:16<00:00, 58.45it/s]\r 98%|█████████▊| 980/1000 [00:17<00:00, 58.28it/s]\r 99%|█████████▊| 986/1000 [00:17<00:00, 58.32it/s]\r 99%|█████████▉| 993/1000 [00:17<00:00, 58.91it/s]\r100%|█████████▉| 999/1000 [00:17<00:00, 59.11it/s]\r100%|██████████| 1000/1000 [00:17<00:00, 57.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcS63jN9RMdy"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that the data is prepared, we can start training!  The training loop tracks FID, but the computations seems to lead to problems in colab. Hence, it is disable by default (```metrics=[]```). The loop also generates fixed noise samples after a defined amount of ticks, eg. below ```--snap=1```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrjw0aes9YV_"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import dnnlib\n",
        "\n",
        "from training import training_loop\n",
        "from torch_utils import training_stats\n",
        "from train import init_dataset_kwargs\n",
        "from metrics import metric_main"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-VAjxpv9s3T"
      },
      "source": [
        "def launch_training(c, desc, outdir, rank=0):\n",
        "    # Pick output directory.\n",
        "    prev_run_dirs = []\n",
        "    if os.path.isdir(outdir):\n",
        "        prev_run_dirs = [x for x in os.listdir(outdir) if os.path.isdir(os.path.join(outdir, x))]\n",
        "\n",
        "    matching_dirs = [re.fullmatch(r'\\d{5}' + f'-{desc}', x) for x in prev_run_dirs if re.fullmatch(r'\\d{5}' + f'-{desc}', x) is not None]\n",
        "    if c.restart_every > 0 and len(matching_dirs) > 0:  # expect unique desc, continue in this directory\n",
        "        assert len(matching_dirs) == 1, f'Multiple directories found for resuming: {matching_dirs}'\n",
        "        c.run_dir = os.path.join(outdir, matching_dirs[0].group())\n",
        "    else:                     # fallback to standard\n",
        "        prev_run_ids = [re.match(r'^\\d+', x) for x in prev_run_dirs]\n",
        "        prev_run_ids = [int(x.group()) for x in prev_run_ids if x is not None]\n",
        "        cur_run_id = max(prev_run_ids, default=-1) + 1\n",
        "        c.run_dir = os.path.join(outdir, f'{cur_run_id:05d}-{desc}')\n",
        "        assert not os.path.exists(c.run_dir)\n",
        "\n",
        "\n",
        "    # Print options.\n",
        "    print()\n",
        "    print('Training options:')\n",
        "    print(json.dumps(c, indent=2))\n",
        "    print()\n",
        "    print(f'Output directory:    {c.run_dir}')\n",
        "    print(f'Number of GPUs:      {c.num_gpus}')\n",
        "    print(f'Batch size:          {c.batch_size} images')\n",
        "    print(f'Training duration:   {c.total_kimg} kimg')\n",
        "    print(f'Dataset path:        {c.training_set_kwargs.path}')\n",
        "    print(f'Dataset size:        {c.training_set_kwargs.max_size} images')\n",
        "    print(f'Dataset resolution:  {c.training_set_kwargs.resolution}')\n",
        "    print(f'Dataset labels:      {c.training_set_kwargs.use_labels}')\n",
        "    print(f'Dataset x-flips:     {c.training_set_kwargs.xflip}')\n",
        "    print()\n",
        "\n",
        "    # Create output directory.\n",
        "    print('Creating output directory...')\n",
        "    os.makedirs(c.run_dir, exist_ok=c.restart_every > 0)\n",
        "    with open(os.path.join(c.run_dir, 'training_options.json'), 'wt+') as f:\n",
        "        json.dump(c, f, indent=2)\n",
        "\n",
        "    # Start training\n",
        "    dnnlib.util.Logger(file_name=os.path.join(c.run_dir, 'log.txt'), file_mode='a', should_flush=False)\n",
        "    sync_device = torch.device('cuda', rank) if c.num_gpus > 1 else None\n",
        "    training_stats.init_multiprocessing(rank=rank, sync_device=sync_device)\n",
        "    training_loop.training_loop(rank=rank, **c)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqqzoKQk9tRt"
      },
      "source": [
        "def train(**kwargs):\n",
        "    # Initialize config.\n",
        "    opts = dnnlib.EasyDict(kwargs) # Command line arguments.\n",
        "    c = dnnlib.EasyDict() # Main config dict.\n",
        "    c.G_kwargs = dnnlib.EasyDict(class_name=None, z_dim=64, w_dim=128, mapping_kwargs=dnnlib.EasyDict())\n",
        "    c.G_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0,0.99], eps=1e-8)\n",
        "    c.D_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0,0.99], eps=1e-8)\n",
        "    c.data_loader_kwargs = dnnlib.EasyDict(pin_memory=True, prefetch_factor=2)\n",
        "\n",
        "    # Training set.\n",
        "    c.training_set_kwargs, dataset_name = init_dataset_kwargs(data=opts.data)\n",
        "    if opts.cond and not c.training_set_kwargs.use_labels:\n",
        "        raise ValueError('--cond=True requires labels specified in dataset.json')\n",
        "    c.training_set_kwargs.use_labels = opts.cond\n",
        "    c.training_set_kwargs.xflip = opts.mirror\n",
        "\n",
        "    # Hyperparameters & settings.\n",
        "    c.num_gpus = opts.gpus\n",
        "    c.batch_size = opts.batch\n",
        "    c.batch_gpu = opts.batch_gpu or opts.batch // opts.gpus\n",
        "    c.G_kwargs.channel_base = opts.cbase\n",
        "    c.G_kwargs.channel_max = opts.cmax\n",
        "    c.G_kwargs.mapping_kwargs.num_layers = 2\n",
        "    c.G_opt_kwargs.lr = (0.002 if opts.cfg == 'stylegan2' else 0.0025) if opts.glr is None else opts.glr\n",
        "    c.D_opt_kwargs.lr = opts.dlr\n",
        "    c.metrics = opts.metrics\n",
        "    c.total_kimg = opts.kimg\n",
        "    c.kimg_per_tick = opts.tick\n",
        "    c.image_snapshot_ticks = c.network_snapshot_ticks = opts.snap\n",
        "    c.random_seed = c.training_set_kwargs.random_seed = opts.seed\n",
        "    c.data_loader_kwargs.num_workers = opts.workers\n",
        "\n",
        "    # Sanity checks.\n",
        "    if c.batch_size % c.num_gpus != 0:\n",
        "        raise ValueError('--batch must be a multiple of --gpus')\n",
        "    if c.batch_size % (c.num_gpus * c.batch_gpu) != 0:\n",
        "        raise ValueError('--batch must be a multiple of --gpus times --batch-gpu')\n",
        "    if any(not metric_main.is_valid_metric(metric) for metric in c.metrics):\n",
        "        raise ValueError('\\n'.join(['--metrics can only contain the following values:'] + metric_main.list_valid_metrics()))\n",
        "\n",
        "    # Base configuration.\n",
        "    c.ema_kimg = c.batch_size * 10 / 32\n",
        "    if opts.cfg == 'stylegan2':\n",
        "        c.G_kwargs.class_name = 'pg_modules.networks_stylegan2.Generator'\n",
        "        c.G_kwargs.fused_modconv_default = 'inference_only' # Speed up training by using regular convolutions instead of grouped convolutions.\n",
        "        use_separable_discs = True\n",
        "\n",
        "    elif opts.cfg == 'fastgan':\n",
        "        c.G_kwargs = dnnlib.EasyDict(class_name='pg_modules.networks_fastgan.Generator', cond=opts.cond)\n",
        "        c.G_opt_kwargs.lr = c.D_opt_kwargs.lr = 0.0002\n",
        "        use_separable_discs = False\n",
        "\n",
        "    # Restart.\n",
        "    c.restart_every = opts.restart_every\n",
        "\n",
        "    # Description string.\n",
        "    desc = f'{opts.cfg:s}-{dataset_name:s}-gpus{c.num_gpus:d}-batch{c.batch_size:d}'\n",
        "    if opts.desc is not None:\n",
        "        desc += f'-{opts.desc}'\n",
        "\n",
        "    # Projected and Multi-Scale Discriminators\n",
        "    c.loss_kwargs = dnnlib.EasyDict(class_name='training.loss.ProjectedGANLoss')\n",
        "    c.D_kwargs = dnnlib.EasyDict(\n",
        "        class_name='pg_modules.discriminator.ProjectedDiscriminator',\n",
        "        diffaug=True,\n",
        "        interp224=(c.training_set_kwargs.resolution < 224),\n",
        "        backbone_kwargs=dnnlib.EasyDict(),\n",
        "    )\n",
        "\n",
        "    c.D_kwargs.backbone_kwargs.cout = 64\n",
        "    c.D_kwargs.backbone_kwargs.expand = True\n",
        "    c.D_kwargs.backbone_kwargs.proj_type = 2\n",
        "    c.D_kwargs.backbone_kwargs.num_discs = 4\n",
        "    c.D_kwargs.backbone_kwargs.separable = use_separable_discs\n",
        "    c.D_kwargs.backbone_kwargs.cond = opts.cond\n",
        "\n",
        "    # Launch.\n",
        "    launch_training(c=c, desc=desc, outdir=opts.outdir)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKHfWFKe9tWB",
        "outputId": "16fa7bc0-df2a-4acc-8add-aee6e8848eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# start training!\n",
        "\n",
        "train(\n",
        "    outdir='training-runs', \n",
        "    cfg='fastgan',\n",
        "    data='./data/art_painting256.zip', \n",
        "    gpus=1, \n",
        "    batch=64, \n",
        "    cond=False, \n",
        "    mirror=1, \n",
        "    batch_gpu=8, \n",
        "    cbase=32768, \n",
        "    cmax=512, \n",
        "    glr=None, \n",
        "    dlr=0.002, \n",
        "    desc='', \n",
        "    metrics=[],\n",
        "    kimg=10000, \n",
        "    tick=4, \n",
        "    snap=1, \n",
        "    seed=0, \n",
        "    workers=0,\n",
        "    restart_every=999999,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"pg_modules.networks_fastgan.Generator\",\n",
            "    \"cond\": false\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0002\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 0\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./data/art_painting256.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1000,\n",
            "    \"xflip\": 1,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 64,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 10000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 1,\n",
            "  \"network_snapshot_ticks\": 1,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 20.0,\n",
            "  \"restart_every\": 999999,\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.ProjectedGANLoss\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"pg_modules.discriminator.ProjectedDiscriminator\",\n",
            "    \"diffaug\": true,\n",
            "    \"interp224\": false,\n",
            "    \"backbone_kwargs\": {\n",
            "      \"cout\": 64,\n",
            "      \"expand\": true,\n",
            "      \"proj_type\": 2,\n",
            "      \"num_discs\": 4,\n",
            "      \"separable\": false,\n",
            "      \"cond\": false\n",
            "    }\n",
            "  },\n",
            "  \"run_dir\": \"training-runs/00000-fastgan-art_painting256-gpus1-batch64-\"\n",
            "}\n",
            "\n",
            "Output directory:    training-runs/00000-fastgan-art_painting256-gpus1-batch64-\n",
            "Number of GPUs:      1\n",
            "Batch size:          64 images\n",
            "Training duration:   10000 kimg\n",
            "Dataset path:        ./data/art_painting256.zip\n",
            "Dataset size:        1000 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  2000\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_lite0-0aa007d2.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_lite0-0aa007d2.pth\n",
            "\n",
            "Generator              Parameters  Buffers  Output shape        Datatype\n",
            "---                    ---         ---      ---                 ---     \n",
            "mapping                -           -        [8, 1, 256]         float32 \n",
            "synthesis.init.init    16785408    16385    [8, 2048, 4, 4]     float32 \n",
            "synthesis.feat_8.0     -           -        [8, 2048, 8, 8]     float32 \n",
            "synthesis.feat_8.1     37748736    20480    [8, 2048, 8, 8]     float32 \n",
            "synthesis.feat_8.2     1           -        [8, 2048, 8, 8]     float32 \n",
            "synthesis.feat_8.3     4096        4097     [8, 2048, 8, 8]     float32 \n",
            "synthesis.feat_8.4     -           -        [8, 1024, 8, 8]     float32 \n",
            "synthesis.feat_8.5     18874368    11264    [8, 2048, 8, 8]     float32 \n",
            "synthesis.feat_8.6     1           -        [8, 2048, 8, 8]     float32 \n",
            "synthesis.feat_8.7     4096        4097     [8, 2048, 8, 8]     float32 \n",
            "synthesis.feat_8.8     -           -        [8, 1024, 8, 8]     float32 \n",
            "synthesis.feat_16.0    -           -        [8, 1024, 16, 16]   float32 \n",
            "synthesis.feat_16.1    9437184     10240    [8, 1024, 16, 16]   float32 \n",
            "synthesis.feat_16.2    1           -        [8, 1024, 16, 16]   float32 \n",
            "synthesis.feat_16.3    2048        2049     [8, 1024, 16, 16]   float32 \n",
            "synthesis.feat_16.4    -           -        [8, 512, 16, 16]    float32 \n",
            "synthesis.feat_16.5    4718592     5632     [8, 1024, 16, 16]   float32 \n",
            "synthesis.feat_16.6    1           -        [8, 1024, 16, 16]   float32 \n",
            "synthesis.feat_16.7    2048        2049     [8, 1024, 16, 16]   float32 \n",
            "synthesis.feat_16.8    -           -        [8, 512, 16, 16]    float32 \n",
            "synthesis.feat_32.0    -           -        [8, 512, 32, 32]    float32 \n",
            "synthesis.feat_32.1    2359296     5120     [8, 512, 32, 32]    float32 \n",
            "synthesis.feat_32.2    1           -        [8, 512, 32, 32]    float32 \n",
            "synthesis.feat_32.3    1024        1025     [8, 512, 32, 32]    float32 \n",
            "synthesis.feat_32.4    -           -        [8, 256, 32, 32]    float32 \n",
            "synthesis.feat_32.5    1179648     2816     [8, 512, 32, 32]    float32 \n",
            "synthesis.feat_32.6    1           -        [8, 512, 32, 32]    float32 \n",
            "synthesis.feat_32.7    1024        1025     [8, 512, 32, 32]    float32 \n",
            "synthesis.feat_32.8    -           -        [8, 256, 32, 32]    float32 \n",
            "synthesis.feat_64.0    -           -        [8, 256, 64, 64]    float32 \n",
            "synthesis.feat_64.1    1179648     2816     [8, 512, 64, 64]    float32 \n",
            "synthesis.feat_64.2    1           -        [8, 512, 64, 64]    float32 \n",
            "synthesis.feat_64.3    1024        1025     [8, 512, 64, 64]    float32 \n",
            "synthesis.feat_64.4    -           -        [8, 256, 64, 64]    float32 \n",
            "synthesis.feat_64.5    1179648     2816     [8, 512, 64, 64]    float32 \n",
            "synthesis.feat_64.6    1           -        [8, 512, 64, 64]    float32 \n",
            "synthesis.feat_64.7    1024        1025     [8, 512, 64, 64]    float32 \n",
            "synthesis.feat_64.8    -           -        [8, 256, 64, 64]    float32 \n",
            "synthesis.se_64.main   8454144     33536    [8, 256, 1, 1]      float32 \n",
            "synthesis.se_64        -           -        [8, 256, 64, 64]    float32 \n",
            "synthesis.feat_128.0   -           -        [8, 256, 128, 128]  float32 \n",
            "synthesis.feat_128.1   589824      2560     [8, 256, 128, 128]  float32 \n",
            "synthesis.feat_128.2   1           -        [8, 256, 128, 128]  float32 \n",
            "synthesis.feat_128.3   512         513      [8, 256, 128, 128]  float32 \n",
            "synthesis.feat_128.4   -           -        [8, 128, 128, 128]  float32 \n",
            "synthesis.feat_128.5   294912      1408     [8, 256, 128, 128]  float32 \n",
            "synthesis.feat_128.6   1           -        [8, 256, 128, 128]  float32 \n",
            "synthesis.feat_128.7   512         513      [8, 256, 128, 128]  float32 \n",
            "synthesis.feat_128.8   -           -        [8, 128, 128, 128]  float32 \n",
            "synthesis.se_128.main  2113536     16768    [8, 128, 1, 1]      float32 \n",
            "synthesis.se_128       -           -        [8, 128, 128, 128]  float32 \n",
            "synthesis.feat_256.0   -           -        [8, 128, 256, 256]  float32 \n",
            "synthesis.feat_256.1   147456      1280     [8, 128, 256, 256]  float32 \n",
            "synthesis.feat_256.2   1           -        [8, 128, 256, 256]  float32 \n",
            "synthesis.feat_256.3   256         257      [8, 128, 256, 256]  float32 \n",
            "synthesis.feat_256.4   -           -        [8, 64, 256, 256]   float32 \n",
            "synthesis.feat_256.5   73728       704      [8, 128, 256, 256]  float32 \n",
            "synthesis.feat_256.6   1           -        [8, 128, 256, 256]  float32 \n",
            "synthesis.feat_256.7   256         257      [8, 128, 256, 256]  float32 \n",
            "synthesis.feat_256.8   -           -        [8, 64, 256, 256]   float32 \n",
            "synthesis.se_256.main  528384      8384     [8, 64, 1, 1]       float32 \n",
            "synthesis.se_256       -           -        [8, 64, 256, 256]   float32 \n",
            "synthesis.to_big       1731        579      [8, 3, 256, 256]    float32 \n",
            "---                    ---         ---      ---                 ---     \n",
            "Total                  105684175   160720   -                   -       \n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "ProjectedDiscriminator                                               Parameters  Buffers  Output shape       Datatype\n",
            "---                                                                  ---         ---      ---                ---     \n",
            "feature_network.pretrained.layer0.0                                  864         -        [8, 32, 128, 128]  float32 \n",
            "feature_network.pretrained.layer0.1                                  64          65       [8, 32, 128, 128]  float32 \n",
            "feature_network.pretrained.layer0.3                                  896         98       [8, 16, 128, 128]  float32 \n",
            "feature_network.pretrained.layer0.4                                  13968       1062     [8, 24, 64, 64]    float32 \n",
            "feature_network.pretrained.layer1.0                                  39712       1702     [8, 40, 32, 32]    float32 \n",
            "feature_network.pretrained.layer2.0                                  198480      5289     [8, 80, 16, 16]    float32 \n",
            "feature_network.pretrained.layer2.1                                  446784      7977     [8, 112, 16, 16]   float32 \n",
            "feature_network.pretrained.layer3.0                                  1652640     18060    [8, 192, 8, 8]     float32 \n",
            "feature_network.pretrained.layer3.1                                  605440      5251     [8, 320, 8, 8]     float32 \n",
            "feature_network.scratch.layer0_ccm                                   1600        -        [8, 64, 64, 64]    float32 \n",
            "feature_network.scratch.layer1_ccm                                   5248        -        [8, 128, 32, 32]   float32 \n",
            "feature_network.scratch.layer2_ccm                                   28928       -        [8, 256, 16, 16]   float32 \n",
            "feature_network.scratch.layer3_ccm                                   164352      -        [8, 512, 8, 8]     float32 \n",
            "feature_network.scratch.layer3_csm.out_conv                          131328      -        [8, 256, 16, 16]   float32 \n",
            "feature_network.scratch.layer2_csm.skip_add.activation_post_process  -           -        [8, 256, 16, 16]   float32 \n",
            "feature_network.scratch.layer2_csm.out_conv                          32896       -        [8, 128, 32, 32]   float32 \n",
            "feature_network.scratch.layer1_csm.skip_add.activation_post_process  -           -        [8, 128, 32, 32]   float32 \n",
            "feature_network.scratch.layer1_csm.out_conv                          8256        -        [8, 64, 64, 64]    float32 \n",
            "feature_network.scratch.layer0_csm.skip_add.activation_post_process  -           -        [8, 64, 64, 64]    float32 \n",
            "feature_network.scratch.layer0_csm.out_conv                          4160        -        [8, 64, 128, 128]  float32 \n",
            "discriminator.mini_discs.0.main                                      2829120     19269    [8, 1, 5, 5]       float32 \n",
            "discriminator.mini_discs.1.main                                      2763392     18052    [8, 1, 5, 5]       float32 \n",
            "discriminator.mini_discs.2.main                                      2631936     16643    [8, 1, 5, 5]       float32 \n",
            "discriminator.mini_discs.3.main                                      2106880     13826    [8, 1, 5, 5]       float32 \n",
            "discriminator                                                        -           -        [8, 100]           float32 \n",
            "---                                                                  ---         ---      ---                ---     \n",
            "Total                                                                13666944    107294   -                  -       \n",
            "\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 10000 kimg...\n",
            "\n",
            "tick 0     kimg 0.1      time 1m 04s       sec/tick 10.5    sec/kimg 164.39  maintenance 53.7   cpumem 5.57   gpumem 6.67   reserved 10.23 \n",
            "tick 1     kimg 4.1      time 8m 52s       sec/tick 449.0   sec/kimg 111.35  maintenance 18.6   cpumem 6.10   gpumem 7.36   reserved 8.86  \n",
            "tick 2     kimg 8.1      time 16m 53s      sec/tick 456.5   sec/kimg 113.21  maintenance 24.6   cpumem 6.18   gpumem 7.36   reserved 8.86  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqYeDzg3KUMG"
      },
      "source": [
        "To inspect the samples, click on the folder symbol on the left and navigate to \n",
        "\n",
        "```projected_gan/training-runs/YOUR_RUN```\n",
        "\n",
        "The files ```fakesXXXXXX.png``` are the samples for a fixed noise vector at point."
      ]
    }
  ]
}